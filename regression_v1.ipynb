{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from mkidreadoutanalysis.quasiparticletimestream import QuasiparticleTimeStream\n",
    "from training import train_step, test_step, make_predictions\n",
    "from eval import accuracy_regression, plot_stream_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the run\n",
    "\n",
    "NO_PULSE_FRACTION = 0.0\n",
    "NUM_SAMPLES = 10000 # This is approximate, the number of photons in the last iteration of the loop is Poisson distributied\n",
    "QP_TIME_LENGTH = 0.01 # secs\n",
    "SAMPLING_FREQ = 2e6 # Hz\n",
    "FALL_TIME = 30\n",
    "EDGE_PAD = FALL_TIME * 2\n",
    "WINDOW_SIZE = 1000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "no_pulses = []\n",
    "pulses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "pulse_list = np.load('data/models/conv_reg/pulses_num10000_win1000_pad60.npz')\n",
    "pulses = list(pulse_list['pulses'])\n",
    "print(len(pulses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets start splitting out the training samples and the label. In this model, we want scalar value for the label, not a time series\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Lets create one big list of the pulse and no pulse samples randomly shuffled together \n",
    "train_data = pulses + no_pulses\n",
    "random.shuffle(train_data)\n",
    "\n",
    "# Now lets separate the training samples (I/Q data) from the label data (photon arrival)\n",
    "for element in train_data:\n",
    "    X.append(element[0:2,:])\n",
    "    y.append(np.argwhere(element[2] == 1) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the training and label data now separated, lets start defining our training/testing metrics\n",
    "# and split the dataset into train and test\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_RATIO, # Ratio of test data to use from full dataset; Training is the complement\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Now lets convert the lists to Tensors. Converting to np arrays first based on warning from torch\n",
    "X_train = torch.Tensor(numpy.array(X_train))\n",
    "X_test = torch.Tensor(numpy.array(X_test))\n",
    "y_train = torch.Tensor(numpy.array(y_train))\n",
    "y_test = torch.Tensor(numpy.array(y_test))\n",
    "\n",
    "print(f'# of train samples: {len(X_train)}, # of test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's finally time to create our Dataloader objects\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Let's first convert from numpy arrays to Tensors and create datasets\n",
    "train_dataset = TensorDataset(X_train,\n",
    "                              y_train)\n",
    "test_dataset = TensorDataset(X_test,\n",
    "                             y_test)\n",
    "\n",
    "train_dloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Now lets inpect the objects.\n",
    "print(f'Type: {type(train_dloader)}')\n",
    "train_batch_img, train_batch_labels = next(iter(train_dloader))\n",
    "print(f'Batch Img: {train_batch_img.shape}, Batch Labels: {train_batch_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ConvRegv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a model instance, loss, and optimizer\n",
    "torch.manual_seed(95)\n",
    "\n",
    "# Adding device agnostic code\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "device\n",
    "\n",
    "conv_reg_v1 = ConvRegv1(in_channels=2)\n",
    "optimizer = torch.optim.SGD(params=conv_reg_v1.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.L1Loss(reduction='mean')# 'mean' reduction takes all the loss values from the batch and averages them to get the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets give the train/test loop a try!\n",
    "\n",
    "# Now lets create a quick little function that gives the run time of the loop\n",
    "total_time = lambda start_time, stop_time: stop_time - start_time\n",
    "\n",
    "EPOCHS = 5\n",
    "train_time_cnn_start = timer()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-----------')\n",
    "    train_step(\n",
    "        conv_reg_v1,\n",
    "        train_dloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        accuracy_regression,\n",
    "        device\n",
    "    )\n",
    "    test_step(\n",
    "        conv_reg_v1,\n",
    "        test_dloader,\n",
    "        loss_fn,\n",
    "        accuracy_regression,\n",
    "        device\n",
    "    )\n",
    "train_time_cnn_end = timer()\n",
    "print(f'Total time to train: {total_time(train_time_cnn_start, train_time_cnn_end):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick n random samples/labels from the test data and plot them\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_dataset), k=15): # random.sample samples k elements from the given population without replacement; returns list of samples.\n",
    "    test_samples.append(sample.to(device))\n",
    "    test_labels.append(label.to(device))\n",
    "\n",
    "print(f'Test Sample Shape: {test_samples[0].shape}, Test Label Shape: {test_labels[0].shape}')\n",
    "preds = make_predictions(conv_reg_v1, [x.unsqueeze(dim=0) for x in test_samples]) # returns a tensor\n",
    "print(f'Preds shape {preds[0].shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    index = (preds[i] * 1000).int()\n",
    "    pred_stream = torch.zeros_like(test_samples[0][0])\n",
    "    pred_stream[index] = 1\n",
    "    plot_stream_data(test_samples[i][0].to('cpu').numpy(),\n",
    "                     test_samples[i][1].to('cpu').numpy(),\n",
    "                     pred_stream.to('cpu').numpy(),\n",
    "                     units='us')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
