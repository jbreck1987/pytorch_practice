{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO-DO: Eliminate using lists and export generated training data for repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mkidreadoutanalysis.resonator import *\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iq(qp_timestream: QuasiparticleTimeStream):\n",
    "    '''\n",
    "    Generate I and Q time streams using the mkidreadoutanalysis library\n",
    "\n",
    "    Inputs: \n",
    "        QuasiPartcileTimeStream object with populated photons\n",
    "    '''\n",
    "\n",
    "    #Creating a resonator object\n",
    "    resonator = Resonator(f0=4.0012e9, qi=200000, qc=15000, xa=1e-9, a=0, tls_scale=1e2)\n",
    "    rf = RFElectronics(gain=(3.0, 0, 0), phase_delay=0, cable_delay=50e-9)\n",
    "    freq = FrequencyGrid( fc=4.0012e9, points=1000, span=500e6)\n",
    "    sweep = ResonatorSweep(resonator, freq, rf)\n",
    "\n",
    "    #Creating Photon Resonator Readout\n",
    "    lit_res_measurment = ReadoutPhotonResonator(resonator, qp_timestream, freq, rf)\n",
    "    lit_res_measurment.noise_on = True #toggle white noise and line noise\n",
    "    lit_res_measurment.rf.noise_scale = 10 #adjust white noise scale\n",
    "\n",
    "    #configure line noise for Resonator\n",
    "    lit_res_measurment.rf.line_noise.freqs = ([60, 50e3, 100e3, 250e3, -300e3, 300e3, 500e3]) # Hz and relative to center of bin (MKID we are reading out)\n",
    "    lit_res_measurment.rf.line_noise.amplitudes = ([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.01])\n",
    "    lit_res_measurment.rf.line_noise.phases = ([0, 0.5, 0,1.3,0.5, 0.2, 2.4])\n",
    "\n",
    "    #Generating Synthetic Data for Output\n",
    "    I = lit_res_measurment.normalized_iq.real\n",
    "    Q = lit_res_measurment.normalized_iq.imag\n",
    "\n",
    "    return I, Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(i: numpy.array,\n",
    "                   q: numpy.array,\n",
    "                   photon_arrivals: numpy.array,\n",
    "                   with_pulses: list,\n",
    "                   no_pulses: list,\n",
    "                   num_samples: int,\n",
    "                   no_pulse_fraction: float,\n",
    "                   window_size=150):\n",
    "    \"\"\"\n",
    "    This function takes the output of the mkidreadoutanalysis objects (I, Q, and Photon Arrival vectors) and chunks it into smaller arrays. The code\n",
    "    also separates chunks with photons and those without photons with the goal of limiting the number of samples\n",
    "    without photon pulses since there are vastly more windows in the synthetic data in this category. It uses \"scanning\" logic to scan over the full\n",
    "    arrays with a given window size and inspects that window for a photon event. The window is then added to the appropriate container (photon/no photon).\n",
    "    \"\"\"\n",
    "\n",
    "    # First determine the last index in the scanning range (need to have length of photon arrivals array be multiple of window_size)\n",
    "    end_index = math.floor(len(photon_arrivals) / window_size) * window_size\n",
    "\n",
    "    # Determine all the indicies in the i,q, photon_arrvial vecs denoting a pulse\n",
    "    pulse_indices = np.argwhere(photon_arrivals == 1).squeeze()\n",
    "\n",
    "    # Now scan across the photon arrival vector and look at windows of length window_size with and without photon events\n",
    "    for window in range(0, end_index - window_size + 1, window_size):\n",
    "        # Check to see if any of the pulse indices are in this window\n",
    "        if np.sum((pulse_indices >= window) & (pulse_indices < window + 150)) > 0:\n",
    "            # If so add the window to the with_pulses container\n",
    "            with_pulses.append(np.vstack((i[window : window + 150],\n",
    "                                          q[window : window + 150],\n",
    "                                          photon_arrivals[window : window + 150])).reshape(3, window_size)) # Reshaping to get in nice form for CNN\n",
    "        # If no pulses are in the window and the no-pulse fraction hasn't been met,\n",
    "        # add to the no_pulses container\n",
    "        elif len(no_pulses) < num_samples * no_pulse_fraction:\n",
    "            no_pulses.append(np.vstack((i[window : window + 150],\n",
    "                                        q[window : window + 150],\n",
    "                                        photon_arrivals[window : window + 150])).reshape(3, window_size)) # Reshaping to get in nice form for CNN\n",
    " \n",
    "    \n",
    "        # Continue to next window doing nothing since threshold for no_pulse samples has been met and the window lacks a pulse\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know the windowing function works, lets build a dataset\n",
    "\n",
    "NO_PULSE_FRACTION = 0.3\n",
    "NUM_SAMPLES = 20000 # This is approximate, the number of photons in the last iteration of the loop is Poisson distributied\n",
    "QP_TIME_LENGTH = 0.01 # secs\n",
    "SAMPLING_FREQ = 2e6 # Hz\n",
    "WINDOW_SIZE = 150\n",
    "RANDOM_SEED = 42\n",
    "no_pulses = []\n",
    "pulses = []\n",
    " \n",
    "# Generating Quasiparticle Timestream\n",
    "quasiparticle_timestream = QuasiparticleTimeStream(SAMPLING_FREQ, QP_TIME_LENGTH, seed=RANDOM_SEED)\n",
    "quasiparticle_timestream.gen_quasiparticle_pulse(tf = 30)\n",
    "\n",
    "# Generate the training set in the following format: [np.array([i,q,label]), ...] where i,q,label are all WINDOW_SIZE length arrays.\n",
    "# Each list element is a 3 x 1 x WINDOW_SIZE numpy array.\n",
    "#print(f'Pulse samples: {NUM_SAMPLES - (NUM_SAMPLES * NO_PULSE_FRACTION)}')\n",
    "#print(f'Noise samples: {NUM_SAMPLES * NO_PULSE_FRACTION}')\n",
    "while len(pulses) < NUM_SAMPLES - (NUM_SAMPLES * NO_PULSE_FRACTION):\n",
    "    # We want the training data to be varied, so lets use the Poisson sampled\n",
    "    # gen_photon_arrivals method to change the photon flux per iteration\n",
    "    photon_arrivals = quasiparticle_timestream.gen_photon_arrivals(cps=2000)\n",
    "    quasiparticle_timestream.populate_photons() # this is necessary for the resonator object in the gen_iq function\n",
    "    I, Q = gen_iq(quasiparticle_timestream)\n",
    "    create_windows(I, Q, photon_arrivals, pulses, no_pulses, NUM_SAMPLES, NO_PULSE_FRACTION, window_size=WINDOW_SIZE)\n",
    "    print(f'Number of samples with pulses so far: {len(pulses)}')\n",
    "    print(f'Number of samples without pulses so far: {len(no_pulses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets inspect some of the windows with pulses\n",
    "#import time\n",
    "#t = np.arange(0, WINDOW_SIZE)\n",
    "#for ind in range(len(pulses)):\n",
    "#    fig, ax = plt.subplots(3,1,figsize = (18,18))\n",
    "#    ax[0].plot(t, pulses[ind][0])\n",
    "#    ax[0].set_xlabel(\"Time (us)\")\n",
    "#    ax[0].set_ylabel(\"I Trace\",fontweight = \"bold\", size = 'large')\n",
    "#\n",
    "#    ax[1].plot(t, pulses[ind][1])\n",
    "#    ax[1].set_xlabel(\"Time (us)\")\n",
    "#    ax[1].set_ylabel(\"Q Trace\",fontweight = \"bold\", size = 'large')\n",
    "#\n",
    "#    ax[2].plot(t, pulses[ind][2])\n",
    "#    ax[2].set_xlabel(\"Time (us)\")\n",
    "#    ax[2].set_ylabel(\"Photon Arrivals (with pulses)\",fontweight = \"bold\", size = 'large')\n",
    "#    plt.show()\n",
    "#    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets inspect some of the windows without pulses\n",
    "#for ind in range(len(pulses)):\n",
    "#    fig, ax = plt.subplots(3,1,figsize = (18,18))\n",
    "#    ax[0].plot(t, no_pulses[ind]['i'])\n",
    "#    ax[0].set_xlabel(\"Time (us)\")\n",
    "#    ax[0].set_ylabel(\"I Trace\",fontweight = \"bold\", size = 'large')\n",
    "#\n",
    "#    ax[1].plot(t, no_pulses[ind]['q'])\n",
    "#    ax[1].set_xlabel(\"Time (us)\")\n",
    "#    ax[1].set_ylabel(\"Q Trace\",fontweight = \"bold\", size = 'large')\n",
    "#\n",
    "#    ax[2].plot(t, no_pulses[ind]['label'])\n",
    "#    ax[2].set_xlabel(\"Time (us)\")\n",
    "#    ax[2].set_ylabel(\"Photon Arrivals (without pulses)\",fontweight = \"bold\", size = 'large')\n",
    "#    plt.show()\n",
    "#    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Lets create one big list of the pulse and no pulse samples randomly shuffled together \n",
    "train_data = pulses + no_pulses\n",
    "shuffle(train_data)\n",
    "\n",
    "# Now lets separate the training samples (I/Q data) from the label data (photon arrival)\n",
    "for element in train_data:\n",
    "    X.append(element[0:2,:])\n",
    "    y.append(element[2].reshape(1,WINDOW_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the training and label data now separated, lets start defining our training/testing metrics\n",
    "# and split the dataset into train and test\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_RATIO, # Ratio of test data to use from full dataset; Training is the complement\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "print(f'# of train samples: {len(X_train)}, # of test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize a few training samples and the associated label to make sure things are looking good before creating the\n",
    "# Dataloader objects\n",
    "import time\n",
    "#t = np.arange(0, WINDOW_SIZE)\n",
    "#for count in range(10):\n",
    "#    fig, ax = plt.subplots(3,1,figsize = (18,18))\n",
    "#    # Choose a random sample from the training set\n",
    "#    ind = torch.randint(0, len(X_train) - 1, size=[1]).item()\n",
    "#    ax[0].plot(t, X_train[ind][0].squeeze())\n",
    "#    ax[0].set_xlabel(\"Time (us)\")\n",
    "#    ax[0].set_ylabel(\"I Trace\",fontweight = \"bold\", size = 'small')\n",
    "#\n",
    "#    ax[1].plot(t, X_train[ind][1].squeeze())\n",
    "#    ax[1].set_xlabel(\"Time (us)\")\n",
    "#    ax[1].set_ylabel(\"Q Trace\",fontweight = \"bold\", size = 'small')\n",
    "#\n",
    "#    ax[2].plot(t, y_train[ind][0].squeeze())\n",
    "#    ax[2].set_xlabel(\"Time (us)\")\n",
    "#    ax[2].set_ylabel(\"Photon Arrivals\",fontweight = \"bold\", size = 'small')\n",
    "#    plt.show()\n",
    "#    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's finally time to create our Dataloader objects\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Let's first convert from numpy arrays to Tensors\n",
    "train_dataset = TensorDataset(torch.Tensor(numpy.array(X_train)),\n",
    "                              torch.Tensor(numpy.array(y_train)))\n",
    "test_dataset = TensorDataset(torch.Tensor(numpy.array(X_test)),\n",
    "                             torch.Tensor(numpy.array(y_test)))\n",
    "\n",
    "train_dloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Now lets inpect the objects. Much of the logic to batch and match labels to input data is done for us in the Dataloader obj\n",
    "print(f'Type: {type(train_dloader)}')\n",
    "train_batch_img, train_batch_labels = next(iter(train_dloader))\n",
    "print(f'Batch Img: {train_batch_img.shape}, Batch Labels: {train_batch_labels.shape}') # So the dloader is basically a list of all the batches and their corressponding labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the training data ready, lets now define the model and the train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder(in_channels)\n",
    "        self.decoder = ConvDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        This class defines the encoder portion of the Convolution Autoencoder network\n",
    "        \"\"\"\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=2, stride=1, padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2) # This is a compression step in this model (1x150 -> 1x75)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3) # The second compression step (1x75 -> 1x25)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=128, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=5) # The second compression step (1x25 -> 1x5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.block3(self.block2(self.block1(x)))\n",
    "        return z\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        This class defines the decoder portion of the Convolution Autoencoder network\n",
    "        \"\"\"\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1, stride=1, padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=5, mode='linear') # First decompression step (1x5 -> 1x25)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=2, stride=1, padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=3, mode='linear') # second decompression step (1x25 -> 1x75)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=1, kernel_size=2, stride=1, padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='linear'), # third decompression step (1x75 -> 1x150)\n",
    "            nn.Sigmoid() # normalize values\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.block3(self.block2(self.block1(x)))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the train/test loop functions\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn):\n",
    "\n",
    "    # Training Steps\n",
    "    loss, acc = 0, 0 # need to reset loss every epoch\n",
    "    for batch, (X, y) in enumerate(data_loader): # each batch has 32 data/labels, create object -> (batch, (X, y))\n",
    "        model.train()\n",
    "        y_pred = model(X) # Like before, need to get model's predictions\n",
    "        loss = loss_fn(y_pred, y) # calculate loss for this batch\n",
    "        loss += loss # add loss from this batch (mean loss of 32 samples) to total loss for the epoch (sum of all batch loss)\n",
    "        acc += accuracy_fn(y_pred, y)\n",
    "\n",
    "        # backprop step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # We want to see some updates within an epoch\n",
    "        print(f'Batches processed: {batch + 1}/{len(data_loader)}, Samples processed: {(batch + 1) * data_loader.batch_size}/{len(data_loader.dataset)}', end='\\r')\n",
    "    \n",
    "    # Now we want to find the AVERAGE loss and accuracy of all the batches\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "    print('\\n-----------')\n",
    "    print(f'Mean Train Loss: {loss:.4f}, Mean Train Accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "\n",
    "    # Test Steps\n",
    "    model.eval()\n",
    "    loss, acc = 0, 0 # need to reset loss every epoch\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader: # each batch has 32 data/labels, create object -> (batch, (X_train, y_train))\n",
    "            y_pred = model(X) # Like before, need to get model's predictions\n",
    "            loss = loss_fn(y_pred, y) # calculate loss for this batch\n",
    "            loss += loss # add loss from this batch (mean loss of 32 samples) to total loss for the epoch (sum of all batch loss)\n",
    "            acc += accuracy_fn(y_pred, y)\n",
    "\n",
    "        # Now we want to find the AVERAGE loss and accuracy of all the batches\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    print(f'Mean Test Loss: {loss:.4f}, Mean Test Accuracy: {acc * 100:.2f}%')\n",
    "    print('-----------\\n')\n",
    "\n",
    "def accuracy_fn(y_pred, y_true):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred))\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define the model, loss function, and optimzer\n",
    "convae_model_v1 = ConvAE(in_channels=2)\n",
    "optimizer = torch.optim.SGD(params=convae_model_v1.parameters(), lr=0.3)\n",
    "loss_fn = nn.L1Loss(reduction='mean')# 'mean' reduction takes all the loss values from the batch and averages them to get the loss\n",
    "convae_model_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets give the train/test loop a try!\n",
    "\n",
    "# Now lets create a quick little function that gives the run time of the loop\n",
    "total_time = lambda start_time, stop_time: stop_time - start_time\n",
    "\n",
    "EPOCHS = 20\n",
    "train_time_cnn_start = timer()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-----------')\n",
    "    train_step(\n",
    "        convae_model_v1,\n",
    "        train_dloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        accuracy_fn\n",
    "    )\n",
    "    test_step(\n",
    "        convae_model_v1,\n",
    "        test_dloader,\n",
    "        loss_fn,\n",
    "        accuracy_fn\n",
    "    )\n",
    "train_time_cnn_end = timer()\n",
    "print(f'Total time to train: {total_time(train_time_cnn_start, train_time_cnn_end):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: nn.Module, samples: list):\n",
    "    \"\"\"\n",
    "    Given a list of samples, returns a list of the prediction for each sample\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        preds_list = [model(x) for x in tqdm(samples, desc=\"Making predictions...\")] \n",
    "        return torch.cat(preds_list) # return as tensor instead of list\n",
    "\n",
    "# Pick n random samples/labels from the test data\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "import random\n",
    "for sample, label in random.sample(list(test_dataset), k=10): # random.sample samples k elements from the given population without replacement; returns list of samples.\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "print(f'Test Sample Shape: {test_samples[0].shape}, Test Label Shape: {test_labels[0].shape}')\n",
    "preds = make_predictions(convae_model_v1, [x.unsqueeze(dim=0) for x in test_samples]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if the model works at all..\n",
    "t = torch.arange(0, 150).squeeze()\n",
    "import time\n",
    "for i in range(len(test_samples)):\n",
    "    fig, ax = plt.subplots(4,1,figsize = (18,18))\n",
    "    ax[0].plot(t, test_samples[i][0])\n",
    "    ax[0].set_xlabel(\"Time (us)\")\n",
    "    ax[0].set_ylabel(\"I Trace\",fontweight = \"bold\", size = 'large')\n",
    "    \n",
    "    ax[1].plot(t, test_samples[i][1])\n",
    "    ax[1].set_xlabel(\"Time (us)\")\n",
    "    ax[1].set_ylabel(\"Q Trace\",fontweight = \"bold\", size = 'large')\n",
    "    \n",
    "    ax[2].plot(t, test_labels[i].squeeze())\n",
    "    ax[2].set_xlabel(\"Time (us)\")\n",
    "    ax[2].set_ylabel(\"Photon Arrivals\",fontweight = \"bold\", size = 'large')\n",
    "    \n",
    "    ax[3].plot(t, preds[i].squeeze())\n",
    "    ax[3].set_xlabel(\"Time (us)\")\n",
    "    ax[3].set_ylabel(\"Photon Arrivals Prediction)\",fontweight = \"bold\", size = 'large')\n",
    "    plt.show()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model doesn't seem to be working, but I think it's a machinery issue, not a design issue. Lets try to simplify the model to use a basic autoencoder (no convolutions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iq_ml_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
