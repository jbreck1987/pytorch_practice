{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "CNNs are great for problems that require classification (and sometimes regression) from visual data. CNNs are useful because *they* find the features themselves as opposed to us determining the features to use. We just give the CNN a label and data that is somewhat visual and let it go.\n",
    "The general flow for this notebook will be:\n",
    "1. Explore tools from PyTorch that allow for the import/transformation of different types of visual data\n",
    "2. Importing data image data from a clothing database\n",
    "3. Design a Multi-Class NN model that will be used to classify the different types of clothing in the images\n",
    "4. Examine the results and then create a CNN model and compare the performance to the MCNN\n",
    "5. Save the weights from model with the best results so that it can be used elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by importing everything we will need\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets # contains pre-built datasets that can be used to test models\n",
    "from torchvision.transforms import ToTensor # contains useful functions that can transfrom common images formats to tensors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(f'PyTorch Version: {torch.__version__}, Torchvision Version: {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get our training and testing data. Turns out torchvision has many built-in datasets already.\n",
    "# We will be using the FashionMNIST dataset for this classification problem. It's basically the fashion\n",
    "# version of the original MNIST dataset that used number. There are 10 classes, but they're clothes, not numbers.\n",
    "\n",
    "DATA_DIR = \"../../data/\"\n",
    "\n",
    "# Many of the datasets in this module have the same arguments.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the training data donwloaded, lets explore\n",
    "print(type(train_data))\n",
    "\n",
    "# Lets get the first image. label combo from the test data\n",
    "image, label = test_data[0]\n",
    "print(f'Label Type: {type(label)}, Label: {label}')\n",
    "print(f'Image Type: {type(image)}, Image Shape: {image.shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So it looks like the image is a 3D tensor and the label is just an integer giving the class. The 1 in the first dimension of the image shows that it's just a greyscale image. This implies that the values in the 28x28 2D tensor just represent the intensity of the the pixel. If this were a color image, there would be 3 \"channels\" representing the intensity of RGB respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset object has useful properties that allow you to view different aspects of the dataset.\n",
    "print(f'Training size: {len(train_data)}, Test size: {len(test_data)}, Test/Train Ratio: {len(test_data)/len(train_data):.2f}')\n",
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets actually look at some of the images/labels in the test dataset\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt_rows = 4\n",
    "plt_cols = 4\n",
    "torch.manual_seed(42)\n",
    "for sub in range(1, plt_rows * plt_cols + 1):\n",
    "    index = torch.randint(0, len(train_data) - 1, size=[1]).item() # Get a random number (in range of the train data)\n",
    "    img, label = train_data[index] # Pull a random test sample and it's label from the training data\n",
    "    fig.add_subplot(plt_rows, plt_cols, sub)\n",
    "    plt.imshow(img.squeeze(), cmap='gray') # Show the image in the subplot. Squeezing out the first dimension, not needed for 2D greyscale\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen above, we have quite a few different images corresponding to the different classes in the dataset! The next step is create a Dataloader object for input into the model we plan to create. This seems like an arbitrary step, why do we need to transform the data into some special object as opposed to just using it as it exists in tensor form? The main reason is due to __Batching__. In most real world scenarios, datasets will be huge. So far, we've been doing a form of training called __Batch Gradient Descent__ where *backprop is done on the entire training set for each epoch*. This is computationally possible with small datasets, but with larger datasets, this would be computationally expensive (thus actually expensive in time and cost). The method we'll be adopting is the use of mini-batching; grouping a very small subset of the entire training set to be used for one backprop step. Instead of the loss from the WHOLE dataset (Batch) or each individual sample (Stochastic) being used to change the weights in the model, the *average* loss of the mini-batch is used. This is effective in reducing the computational load and to prevent issues like overfitting. Moving our data to a Dataloader object allows for us to easily change the batch size and to allow for shuffling the data around for each epoch (epoch # = mini-batch #)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders obj for both training and test\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Now lets inpect the objects. Much of the logic to batch and match labels to input data is done for us in the Dataloader obj\n",
    "print(f'Type: {type(train_dloader)}')\n",
    "train_batch_img, train_batch_labels = next(iter(train_dloader))\n",
    "print(f'Batch Img: {train_batch_img.shape}, Batch Labels: {train_batch_labels.shape}') # So the dloader is basically a list of all the batches and their corressponding labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "With all the data import and preparation done, we can now create a baseline (very simple) model. Will start with a basic 2 layer network, one hidden layer, with a flattening layer as the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMS = train_data[0][0].shape[1]*train_data[0][0].shape[2] # our images are 28*28 and will be flattened out before hitting the NN\n",
    "HIDDEN_UNITS = 10\n",
    "OUTPUT_DIMS = len(train_data.classes)\n",
    "\n",
    "class FashionMNISTModel0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_shape: int,\n",
    "                 out_shape: int,\n",
    "                 hidden_units: int) -> None:\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=in_shape, out_features=hidden_units, bias=True),\n",
    "            nn.Linear(in_features=hidden_units, out_features=out_shape, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "fmnist_model_0 = FashionMNISTModel0(in_shape=INPUT_DIMS,\n",
    "                               out_shape=OUTPUT_DIMS,\n",
    "                               hidden_units=HIDDEN_UNITS)\n",
    "print(fmnist_model_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to once again define the optimizer/loss function combo\n",
    "optimizer = torch.optim.SGD(params=fmnist_model_0.parameters(), lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss() # 'mean' reduction takes all the loss values from the batch and averages them to get the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's training loop time. Since we're using a slightly different model architecture with mini-batches,\n",
    "# will write out all steps. Mini-batches require a nested loop for each epoch.\n",
    "from timeit import default_timer as timer # boilerplate timer functionality\n",
    "from tqdm.auto import tqdm # text-based progress bar\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Now lets create a quick little function that gives the run time of the loop\n",
    "total_time = lambda start_time, stop_time: stop_time - start_time\n",
    "\n",
    "torch.manual_seed(42)\n",
    "EPOCHS = 2\n",
    "train_size = len(train_dloader.dataset) # number of samples in the train dataset\n",
    "test_size = len(test_dloader.dataset) # number of samples in test dataset\n",
    "num_batches_train = train_size/BATCH_SIZE\n",
    "num_batches_test = test_size/BATCH_SIZE\n",
    "acc = Accuracy(task='multiclass', num_classes=len(test_data.classes))\n",
    "\n",
    "train_time_mnn_start = timer()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-----------')\n",
    "\n",
    "    # Training Steps\n",
    "    train_loss = 0 # need to reset loss every epoch\n",
    "    for batch, (X_train, y_train) in enumerate(train_dloader): # each batch has 32 data/labels, create object -> (batch, (X_train, y_train))\n",
    "        fmnist_model_0.train()\n",
    "        \n",
    "        y_logits = fmnist_model_0(X_train) # Like before, need to get model's predictions (in logits)\n",
    "        loss = loss_fn(y_logits, y_train) # calculate loss for this batch\n",
    "        train_loss += loss # add loss from this batch (mean loss of 32 samples) to total loss for the epoch (sum of all batch loss)\n",
    "\n",
    "        # backprop step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # We want to see some updates within an epoch\n",
    "        print(f'Batches processed: {batch + 1}/{int(num_batches_train)}, Samples processed: {(batch + 1) * BATCH_SIZE}/{train_size}', end='\\r')\n",
    "    \n",
    "    # Now we want to find the AVERAGE loss of all the batches\n",
    "    train_loss /= num_batches_train\n",
    "\n",
    "    # Test Steps; mimick the training steps without backprop.\n",
    "    # Only care about the epoch level values for test, no intermediate\n",
    "    # updates necessary.\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    fmnist_model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dloader:\n",
    "            test_logits = fmnist_model_0(X_test)\n",
    "            test_loss += loss_fn(test_logits, y_test) # Note, no need for batch loss variable since we don't care about per batch backprop when testing\n",
    "            test_acc += acc(test_logits, y_test) # acc expects input tensors denoting labels, need to convert from logits\n",
    "\n",
    "        # Get AVERAGE loss and accuracy off all test batches\n",
    "        test_loss /= num_batches_test \n",
    "        test_acc /= num_batches_test \n",
    "\n",
    "        # print out test loss and test accuracy\n",
    "    print('\\n-----------')\n",
    "    print(f'Mean Test Loss: {test_loss:.4f}')\n",
    "    print(f'Mean Test Accuracy: {test_acc * 100:.2f}%')\n",
    "    print('-----------\\n')\n",
    "train_time_mnn_end = timer()\n",
    "print(f'Total time to train: {total_time(train_time_mnn_start, train_time_mnn_end):.2f}s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems like the baseline model is doing a decent job, but lets see if we can make it any better by adding non-linearity to the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the train/test loop has gotten more complex, lets turn the steps into functions\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn):\n",
    "\n",
    "    # Training Steps\n",
    "    loss, acc = 0, 0 # need to reset loss every epoch\n",
    "    for batch, (X, y) in enumerate(data_loader): # each batch has 32 data/labels, create object -> (batch, (X, y))\n",
    "        model.train()\n",
    "        y_pred = model(X) # Like before, need to get model's predictions (in logits)\n",
    "        loss = loss_fn(y_pred, y) # calculate loss for this batch\n",
    "        loss += loss # add loss from this batch (mean loss of 32 samples) to total loss for the epoch (sum of all batch loss)\n",
    "        acc += accuracy_fn(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        # backprop step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # We want to see some updates within an epoch\n",
    "        print(f'Batches processed: {batch + 1}/{len(data_loader)}, Samples processed: {(batch + 1) * data_loader.batch_size}/{len(data_loader.dataset)}', end='\\r')\n",
    "    \n",
    "    # Now we want to find the AVERAGE loss and accuracy of all the batches\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "    print('\\n-----------')\n",
    "    print(f'Mean Train Loss: {loss:.4f}, Mean Train Accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "\n",
    "    # Test Steps\n",
    "    model.eval()\n",
    "    loss, acc = 0, 0 # need to reset loss every epoch\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader: # each batch has 32 data/labels, create object -> (batch, (X_train, y_train))\n",
    "            y_pred = model(X) # Like before, need to get model's predictions (in logits)\n",
    "            loss = loss_fn(y_pred, y) # calculate loss for this batch\n",
    "            loss += loss # add loss from this batch (mean loss of 32 samples) to total loss for the epoch (sum of all batch loss)\n",
    "            acc += accuracy_fn(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        # Now we want to find the AVERAGE loss and accuracy of all the batches\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    print(f'Mean Test Loss: {loss:.4f}, Mean Test Accuracy: {acc * 100:.2f}%')\n",
    "    print('-----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try out new functions out in an identical training loop as before\n",
    "# Now it's training loop time. Since we're using a slightly different model architecture with mini-batches,\n",
    "# will write out all steps. Mini-batches require a nested loop for each epoch.\n",
    "\n",
    "from helper_functions import model_accuracy\n",
    "torch.manual_seed(42)\n",
    "EPOCHS = 2\n",
    "train_time_mnn_start = timer()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-----------')\n",
    "    train_step(\n",
    "        fmnist_model_0,\n",
    "        train_dloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        model_accuracy\n",
    "    )\n",
    "    test_step(\n",
    "        fmnist_model_0,\n",
    "        test_dloader,\n",
    "        loss_fn,\n",
    "        model_accuracy\n",
    "    )\n",
    "train_time_mnn_end = timer()\n",
    "print(f'Total time to train: {total_time(train_time_mnn_start, train_time_mnn_end):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this simplified training/testing loop code, lets define a new model with non-linearities and try to test it again\n",
    "INPUT_DIMS = train_data[0][0].shape[1]*train_data[0][0].shape[2] # our images are 28*28 and will be flattened out before hitting the NN\n",
    "HIDDEN_UNITS = 10\n",
    "OUTPUT_DIMS = len(train_data.classes)\n",
    "\n",
    "class FashionMNISTModel1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_shape: int,\n",
    "                 out_shape: int,\n",
    "                 hidden_units: int) -> None:\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=in_shape, out_features=hidden_units, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=out_shape, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "fmnist_model_1 = FashionMNISTModel1(in_shape=INPUT_DIMS,\n",
    "                               out_shape=OUTPUT_DIMS,\n",
    "                               hidden_units=HIDDEN_UNITS)\n",
    "print(fmnist_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "optimizer_v1 = torch.optim.SGD(params=fmnist_model_1.parameters(), lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss() # 'mean' reduction takes all the loss values from the batch and averages them to get the loss\n",
    "\n",
    "EPOCHS = 2\n",
    "train_time_mnn_start = timer()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-----------')\n",
    "    train_step(\n",
    "        fmnist_model_1,\n",
    "        train_dloader,\n",
    "        loss_fn,\n",
    "        optimizer_v1,\n",
    "        model_accuracy\n",
    "    )\n",
    "    test_step(\n",
    "        fmnist_model_1,\n",
    "        test_dloader,\n",
    "        loss_fn,\n",
    "        model_accuracy\n",
    "    )\n",
    "train_time_mnn_end = timer()\n",
    "print(f'Total time to train: {total_time(train_time_mnn_start, train_time_mnn_end):.2f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iq_ml_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
