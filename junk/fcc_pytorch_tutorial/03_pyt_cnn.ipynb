{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "CNNs are great for problems that require classification (and sometimes regression) from visual data. CNNs are useful because *they* find the features themselves as opposed to us determining the features to use. We just give the CNN a label and data that is somewhat visual and let it go.\n",
    "The general flow for this notebook will be:\n",
    "1. Explore tools from PyTorch that allow for the import/transformation of different types of visual data\n",
    "2. Importing data image data from a clothing database\n",
    "3. Design a Multi-Class NN model that will be used to classify the different types of clothing in the images\n",
    "4. Examine the results and then create a CNN model and compare the performance to the MCNN\n",
    "5. Save the weights from model with the best results so that it can be used elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by importing everything we will need\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets # contains pre-built datasets that can be used to test models\n",
    "from torchvision.transforms import ToTensor # contains useful functions that can transfrom common images formats to tensors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(f'PyTorch Version: {torch.__version__}, Torchvision Version: {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get our training and testing data. Turns out torchvision has many built-in datasets already.\n",
    "# We will be using the FashionMNIST dataset for this classification problem. It's basically the fashion\n",
    "# version of the original MNIST dataset that used number. There are 10 classes, but they're clothes, not numbers.\n",
    "\n",
    "DATA_DIR = \"../../data/\"\n",
    "\n",
    "# Many of the datasets in this module have the same arguments.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the training data donwloaded, lets explore\n",
    "print(type(train_data))\n",
    "\n",
    "# Lets get the first image. label combo from the test data\n",
    "image, label = test_data[0]\n",
    "print(f'Label Type: {type(label)}, Label: {label}')\n",
    "print(f'Image Type: {type(image)}, Image Shape: {image.shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So it looks like the image is a 3D tensor and the label is just an integer giving the class. The 1 in the first dimension of the image shows that it's just a greyscale image. This implies that the values in the 28x28 2D tensor just represent the intensity of the the pixel. If this were a color image, there would be 3 \"channels\" representing the intensity of RGB respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset object has useful properties that allow you to view different aspects of the dataset.\n",
    "print(f'Training size: {len(train_data)}, Test size: {len(test_data)}, Test/Train Ratio: {len(test_data)/len(train_data):.2f}')\n",
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets actually look at some of the images/labels in the test dataset\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt_rows = 4\n",
    "plt_cols = 4\n",
    "torch.manual_seed(42)\n",
    "for sub in range(1, plt_rows * plt_cols + 1):\n",
    "    index = torch.randint(0, len(train_data) - 1, size=[1]).item() # Get a random number (in range of the train data)\n",
    "    img, label = train_data[index] # Pull a random test sample and it's label from the training data\n",
    "    fig.add_subplot(plt_rows, plt_cols, sub)\n",
    "    plt.imshow(img.squeeze(), cmap='gray') # Show the image in the subplot\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen above, we have quite a few different images corresponding to the different classes in the dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iq_ml_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
