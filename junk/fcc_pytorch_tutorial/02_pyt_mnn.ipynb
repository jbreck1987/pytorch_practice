{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Classification\n",
    "Now that we've explored a binary classification problem with linear and non-linear architectures, we now want to shift to a multi-class problem where there are more than two options that the model needs to be able to classify.\n",
    "\n",
    "The multi-class data will be artificial data from the scikit-learn `make_blobs()` function. The general flow is as follows:\n",
    "1. Make the artificial data and convert to tensors\n",
    "2. Visualize the data\n",
    "3. Define the model architecture\n",
    "4. Train the model\n",
    "5. Adjust hyperparameters as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets explore the make_blobs() function. According to the documentation,\n",
    "# make_blobs is designed for creating artificial multiclass data by creating isotropic, Gaussian clusters\n",
    "# of points. The data is quite literally \"blobs\" of points around a \"center\" in R^n space. The classes could be based \n",
    "# on the number of centers in a feature set.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "n_points = 50\n",
    "X_blob, y_blob = make_blobs([n_points, n_points], # array length = num blobs, n_points = points per blob\n",
    "                            n_features=3,\n",
    "                            centers=None, random_state=42) # returns coordinates of points (X) and its blob membership\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('Two blobs with 3 features (x, y, z)')\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X_blob[:,0], X_blob[:,1], X_blob[:, 2], c=y_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets standardize this a little for the actual model. Will define the const values that will be used when creating\n",
    "# the architecture (allow things to be updated once). This could probably eventually be refactored into a dataclass.\n",
    "\n",
    "NUM_CLASSES = 4 # This is self explanatory, the number of blobs per training data instance\n",
    "CLUSTER_POINTS = 100 # This is the number of points that are in each blob\n",
    "NUM_FEATURES = 2 # This refers to the dimension of the data. In this case, the dimension of the the points in the blobs (the above example is 3D)\n",
    "CLUSTER_STD_DEV = 1.0 # This changes the spread in each blob (makes classification more difficult!)\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_TEST_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create our training data and move to tensors\n",
    "X_blob, y_blob = make_blobs([CLUSTER_POINTS for centers in range(NUM_CLASSES)],\n",
    "                            n_features=NUM_FEATURES,\n",
    "                            centers=None,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            cluster_std=CLUSTER_STD_DEV)\n",
    "\n",
    "X_blob = torch.from_numpy(X_blob).type(torch.float)\n",
    "y_blob = torch.from_numpy(y_blob).type(torch.float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_blob,\n",
    "    y_blob,\n",
    "    test_size=TRAIN_TEST_RATIO, # Ratio of test data to use from full dataset; Training is the complement\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets inspect our dataset to make sure it looks as expected\n",
    "print(X_train[0:9]) # expect coordinates from R^2\n",
    "print(y_train[0:14]) # expect values from 0-3\n",
    "print(f'X ratio: {len(X_test)/len(X_train)}, y ratio: {len(y_test)/len(y_train)}') # should be ~0.2\n",
    "for obj in [X_train, X_test, y_train, y_test]: # expecting all to be torch.float\n",
    "    print(obj.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the dataset properties look good, lets visualize it!\n",
    "fig = plt.figure()\n",
    "base_title = f'{NUM_CLASSES} blobs with {NUM_FEATURES} features'\n",
    "if NUM_FEATURES >= 3:\n",
    "    plt.title(base_title + ' (first 3 dims.)')\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], X_train[:, 2], c=y_train)\n",
    "elif NUM_FEATURES == 2:\n",
    "    plt.title(base_title)\n",
    "    plt.scatter(X_train[:,0], X_train[:,1], c=y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iq_ml_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
